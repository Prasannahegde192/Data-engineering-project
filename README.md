# ğŸ§¹ Olist Data Cleaning & Transformation

Transforming the raw Olist eâ€‘commerce dataset into clean, analysis-ready tables using Python, PySpark, and Databricks.

---

## ğŸ“ Overview

This project focuses on implementing comprehensive **data cleaning and transformation** steps on the Olist datasetâ€”a realâ€‘world Brazilian eâ€‘commerce database. The notebook (ğŸ“˜ `olyst data cleaning.ipynb`) walks through:

- âœ… Data ingestion  
- âœ… Handling missing values, duplicates, and outliers  
- âœ… Data type conversions and standardizations  
- âœ… Joining multiple tables (orders, customers, payments, reviews, etc.)  
- âœ… Generating clean, usable tables for downstream analytics  

---

## ğŸ” What You'll See

1. **Data Profiling**:  
   - Exploratory checks for nulls and anomalies  
2. **Cleaning Techniques**:  
   - Dropping duplicates  
   - Imputing or removing nulls  
   - Fixing inconsistent formats (dates, currency)  
3. **Transformation Logic**:  
   - Data type casting (e.g., timestamp parsing)  
   - Creating derived columns (e.g., delivery time, order intervals)  
   - Joining across tables for enriched datasets  
4. **Output**:  
   - Clean tables ready for loading into a data warehouse or analytics tool

---

## ğŸ› ï¸ Tools & Tech

- **ğŸ Python** + **Pandas** & **PySpark** (Databricksâ€”leveraging its scalability)
- **Databricks notebook** environment (`olyst data cleaning.ipynb`)
- Recommended for:
  - Large-scale dataset transformations  
  - Reusable ETL pipelines in Databricks  

---

## ğŸš€ How to Run

1. Clone this repo and open `olyst data cleaning.ipynb` in Databricks.
2. Install dependencies:  
   ```bash
   pip install pyspark pandas
